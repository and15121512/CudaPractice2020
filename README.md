1) Исходный код оптимизированной версии находится в shared.cu, наивной -- в naive.cu. Входные данные -- результаты работы функций
fillMatrixA и fillMatrixB, которые должны заполнить переданные им матрицы (хранятся в одномерном массиве, последовательно по строкам).
Результат выводится в виде трёх столбцов: номер строки, номер столбца, значение элемента.

2) Для оптимизации: 

*  входная матрица B транспонируется
*  строки и столбцы, необходимые для подсчёта соответствующих одному блоку элементов результатирующей матрицы C (позиция вычисляемого элемента текущим потоком -- позиция самого этого потока в grid`е), копируются в shared memory этого блока.
*  для копирования элементов в shared memory полоса (набор строк) разделяется между потоками поровну (с точностью до последнего, ему меньше)

3) Время работы замерялось с помощью nvprof; само перемножение матриц на GPU (с учётом транспонирования) работает примерно в $` 1.5 `$ раза быстрее при
использовании shared memory, чем при наивной реализации. Единственный недостаток: для перемножения больших матриц следует учитывать размер доступной
shared memory одного блока.